"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  NKOTRONIC BACKEND - Version ComplÃ¨te                       â•‘
â•‘  Prompt systÃ¨me: TOUTES les 864 lignes du document         â•‘
â•‘  Lexique: ChargÃ© dynamiquement depuis GitHub                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import openai
import os
import httpx
from typing import List, Optional

app = FastAPI(title="Nkotronic API", version="2.0.0")

# CORS pour permettre les requÃªtes depuis le frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CHARGEMENT DU PROMPT SYSTÃˆME COMPLET (864 lignes)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Lire le fichier complet au dÃ©marrage
SYSTEM_PROMPT_PATH = "/mnt/user-data/uploads/Tu_es_Nkotronic__l_IA__Tu_es_Nkotro.txt"

try:
    with open(SYSTEM_PROMPT_PATH, 'r', encoding='utf-8') as f:
        NKOTRONIC_COMPLETE_GRAMMAR = f.read()
    print(f"âœ… Prompt systÃ¨me chargÃ©: {len(NKOTRONIC_COMPLETE_GRAMMAR)} caractÃ¨res")
except Exception as e:
    print(f"âŒ ERREUR: Impossible de charger le prompt systÃ¨me: {e}")
    NKOTRONIC_COMPLETE_GRAMMAR = ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CHARGEMENT DU LEXIQUE DEPUIS GITHUB
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GITHUB_LEXIQUE_URL = "https://raw.githubusercontent.com/Nkotronic/nkotronic-api/main/vocab_fr_nko.txt"

# Cache du lexique pour Ã©viter de le recharger Ã  chaque requÃªte
LEXIQUE_CACHE = None

async def load_lexique(force_reload: bool = False):
    """Charge le lexique depuis GitHub avec cache"""
    global LEXIQUE_CACHE
    
    if LEXIQUE_CACHE is not None and not force_reload:
        return LEXIQUE_CACHE
    
    try:
        async with httpx.AsyncClient() as client:
            print("ğŸ“¥ Chargement du lexique depuis GitHub...")
            response = await client.get(GITHUB_LEXIQUE_URL, timeout=30.0)
            response.raise_for_status()
            LEXIQUE_CACHE = response.text
            print(f"âœ… Lexique chargÃ©: {len(LEXIQUE_CACHE)} caractÃ¨res")
            return LEXIQUE_CACHE
    except Exception as e:
        print(f"âŒ Erreur chargement lexique: {e}")
        return "# Lexique temporairement indisponible\n# Utilise uniquement les connaissances de la grammaire."

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODÃˆLES PYDANTIC
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Message(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    message: str
    conversation_history: List[Message] = []
    model: str = "gpt-4o"  # ou "gpt-4o-mini" pour Ã©conomiser
    temperature: float = 0.3
    max_tokens: int = 4096

class ChatResponse(BaseModel):
    response: str
    model_used: str
    tokens_used: Optional[int] = None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONSTRUCTION DU CONTEXTE COMPLET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def build_full_context():
    """Construit le contexte complet: Grammaire (864 lignes) + Lexique"""
    
    lexique = await load_lexique()
    
    full_context = f"""{NKOTRONIC_COMPLETE_GRAMMAR}

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š LEXIQUE VOCABULAIRE FRANÃ‡AIS-N'KO                       â•‘
â•‘  (PrioritÃ© absolue sur ton prÃ©-entraÃ®nement GPT)           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{lexique}

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âš¡ RÃˆGLES DE COMPORTEMENT FINALES                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. TOUJOURS utiliser la grammaire N'ko ci-dessus (864 lignes complÃ¨tes)
2. TOUJOURS utiliser le lexique ci-dessus pour les traductions
3. Si un mot N'ko n'est PAS dans le lexique, dire: "Je ne connais pas encore ce mot dans mon lexique"
4. NE JAMAIS inventer de traductions basÃ©es sur ton prÃ©-entraÃ®nement GPT
5. NE JAMAIS dire "Le N'ko est un alphabet" sans mentionner que c'est AUSSI une langue
6. TOUJOURS appliquer correctement le dÃ¶yÃ¨lÃ¨man (mutation)
7. TOUJOURS appliquer correctement le gbarali (association)
8. TOUJOURS respecter les structures de conjugaison exactes
9. ÃŠtre bienveillant et pÃ©dagogue dans tes corrections
10. Respecter l'hÃ©ritage de Solomana KantÃ©

Tu es le gardien de la puretÃ© du N'ko. Toutes tes rÃ©ponses doivent Ãªtre exactes et fidÃ¨les Ã  ces enseignements.
"""
    
    return full_context

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENDPOINT PRINCIPAL DE CHAT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Endpoint principal de conversation avec Nkotronic
    
    - Charge automatiquement les 864 lignes de grammaire
    - Charge le lexique depuis GitHub
    - Utilise GPT-4o ou GPT-4o-mini
    - GÃ¨re l'historique de conversation
    """
    try:
        # VÃ©rifier que la clÃ© API OpenAI est configurÃ©e
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise HTTPException(
                status_code=500, 
                detail="OPENAI_API_KEY not configured"
            )
        
        # Construire le contexte complet
        full_context = await build_full_context()
        
        # PrÃ©parer les messages pour OpenAI
        messages = [{"role": "system", "content": full_context}]
        
        # Ajouter l'historique de conversation
        for msg in request.conversation_history:
            messages.append({"role": msg.role, "content": msg.content})
        
        # Ajouter le message actuel
        messages.append({"role": "user", "content": request.message})
        
        # Appel Ã  OpenAI
        client = openai.OpenAI(api_key=api_key)
        
        completion = client.chat.completions.create(
            model=request.model,
            messages=messages,
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        
        response_text = completion.choices[0].message.content
        tokens_used = completion.usage.total_tokens if completion.usage else None
        
        return ChatResponse(
            response=response_text,
            model_used=request.model,
            tokens_used=tokens_used
        )
        
    except openai.APIError as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API Error: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error: {str(e)}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENDPOINTS UTILITAIRES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/health")
async def health():
    """VÃ©rifier l'Ã©tat du service"""
    return {
        "status": "healthy",
        "grammar_loaded": len(NKOTRONIC_COMPLETE_GRAMMAR) > 0,
        "grammar_size": len(NKOTRONIC_COMPLETE_GRAMMAR),
        "lexique_cached": LEXIQUE_CACHE is not None,
        "default_model": "gpt-4o"
    }

@app.post("/reload-lexique")
async def reload_lexique():
    """Forcer le rechargement du lexique depuis GitHub"""
    lexique = await load_lexique(force_reload=True)
    return {
        "status": "reloaded",
        "lexique_size": len(lexique)
    }

@app.get("/info")
async def info():
    """Informations sur Nkotronic"""
    return {
        "name": "Nkotronic",
        "version": "2.0.0",
        "description": "Intelligence Artificielle experte en N'ko",
        "creator": "Holding Nkowuruki",
        "grammar_lines": 864,
        "models_available": ["gpt-4o", "gpt-4o-mini"],
        "features": [
            "Grammaire N'ko complÃ¨te (864 lignes)",
            "Lexique franÃ§ais-N'ko dynamique",
            "Application correcte du dÃ¶yÃ¨lÃ¨man",
            "Application correcte du gbarali",
            "Conjugaison des 7 temps",
            "Corrections bienveillantes"
        ]
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LANCEMENT DU SERVEUR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import uvicorn
    
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘           ğŸš€ NKOTRONIC API - Version ComplÃ¨te               â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"Grammaire: {len(NKOTRONIC_COMPLETE_GRAMMAR)} caractÃ¨res chargÃ©s")
    print("Lexique: ChargÃ© dynamiquement depuis GitHub")
    print("ModÃ¨le: gpt-4o / gpt-4o-mini")
    print("Port: 8000")
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)