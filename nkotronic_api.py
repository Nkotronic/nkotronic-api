"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
NKOTRONIC BACKEND - VERSION OPTIMISÃ‰E
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… ModÃ¨le : gemini-2.5-flash
âœ… System prompt optimisÃ© pour rÃ©ponses rapides
âœ… Gestion intelligente de l'historique (limite Ã  20 messages)
âœ… Endpoint /health avec cold start detection
âœ… Message systÃ¨me intÃ©grÃ© dans l'historique
âœ… Cleanup automatique des sessions
âœ… Variable FIRST_REQUEST correctement initialisÃ©e
âœ… Streaming SSE optimisÃ©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import google.generativeai as genai
import os
import json
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VARIABLES GLOBALES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

sessions: Dict[str, 'SessionData'] = {}
SERVER_START_TIME = datetime.now()
FIRST_REQUEST = True
LOADING_STATUS = {
    "grammar_loaded": False,
    "grammar_load_time": None
}

# Configuration de l'historique
MAX_HISTORY_MESSAGES = 20  # âœ… Limite Ã  20 messages (10 Ã©changes user/model)

# Message systÃ¨me affichÃ© Ã  l'utilisateur
SYSTEM_MESSAGE = "Alu ni djÃ¶ ! Je suis Nkotronic, votre assistant du N'ko. Que puis-je faire pour vous ?"

# âœ… System prompt optimisÃ© pour guider le modÃ¨le (invisible pour l'utilisateur)
SYSTEM_PROMPT = """Tu es Nkotronic, un assistant spÃ©cialisÃ© dans l'Ã©criture N'ko, la culture africaine et la culture mandingue. Tu es citoyen de l'Etat FÃ©dÃ©ral Africain

DIRECTIVES DE RÃ‰PONSE:
- RÃ©ponds de maniÃ¨re concise et directe
- PrivilÃ©gie les rÃ©ponses courtes (2-3 phrases) sauf si l'utilisateur demande des dÃ©tails approfondis
- Pour les traductions, donne le rÃ©sultat immÃ©diatement sans explications superflues
- Pour les questions de grammaire N'ko, sois prÃ©cis et pÃ©dagogique mais concis
- Maintiens un ton amical et professionnel
- Si tu ne connais pas la rÃ©ponse exacte, dis-le honnÃªtement en une phrase

EXPERTISE:
- Ã‰criture et alphabet N'ko (ß’ßß)
- Grammaire mandingue (Bambara, MalinkÃ©, Dioula)
- Culture et histoire africaine et mandingue
- Traduction franÃ§ais â†” N'ko

STYLE:
- Fluide et naturel
- Pas de longs prÃ©ambules
- Va droit au but
- Utilise des exemples concrets quand nÃ©cessaire"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION GEMINI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("âŒ GEMINI_API_KEY manquante dans les variables d'environnement")

genai.configure(api_key=GEMINI_API_KEY)

# Configuration de sÃ©curitÃ©
safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODÃˆLES DE DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SessionData(BaseModel):
    session_id: str
    history: List[dict]
    created_at: datetime
    last_activity: datetime
    message_count: int = 0

class ChatRequest(BaseModel):
    message: str
    session_id: str = "default"
    model: str = "gemini-2.5-flash"
    temperature: float = 0.7
    max_tokens: int = 4000

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASTAPI APP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = FastAPI(title="Nkotronic API", version="2.1.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FONCTIONS UTILITAIRES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def cleanup_old_sessions():
    """Nettoie les sessions inactives depuis plus de 24h"""
    now = datetime.now()
    to_delete = []
    
    for session_id, session in sessions.items():
        if (now - session.last_activity) > timedelta(hours=24):
            to_delete.append(session_id)
    
    for session_id in to_delete:
        del sessions[session_id]
        logger.info(f"ğŸ—‘ï¸  Session supprimÃ©e: {session_id}")
    
    if to_delete:
        logger.info(f"ğŸ§¹ Nettoyage: {len(to_delete)} session(s) supprimÃ©e(s)")

def truncate_history(history: List[dict], max_messages: int = MAX_HISTORY_MESSAGES) -> List[dict]:
    """
    âœ… Tronque l'historique intelligemment pour garder les N derniers messages
    
    Garde toujours:
    1. Le system prompt (premier message)
    2. Le message de bienvenue (deuxiÃ¨me message)
    3. Les N derniers Ã©changes
    
    Args:
        history: L'historique complet
        max_messages: Nombre maximum de messages Ã  garder (aprÃ¨s system prompt)
    
    Returns:
        Historique tronquÃ©
    """
    if len(history) <= max_messages + 2:  # +2 pour system prompt et message bienvenue
        return history
    
    # Garder: [system_prompt, welcome_message, ...derniers N messages]
    system_messages = history[:2]  # System prompt + message bienvenue
    recent_messages = history[-(max_messages):]  # Les N derniers messages
    
    truncated = system_messages + recent_messages
    
    logger.info(f"ğŸ“ Historique tronquÃ©: {len(history)} â†’ {len(truncated)} messages")
    
    return truncated

def get_session(session_id: str, initialize: bool = False) -> SessionData:
    """RÃ©cupÃ¨re ou crÃ©e une session"""
    cleanup_old_sessions()
    
    if session_id not in sessions:
        if not initialize:
            raise HTTPException(status_code=404, detail=f"Session {session_id} introuvable")
        
        # âœ… CrÃ©er nouvelle session avec system prompt et message bienvenue
        sessions[session_id] = SessionData(
            session_id=session_id,
            history=[
                # System prompt (invisible pour l'utilisateur)
                {"role": "user", "parts": [{"text": SYSTEM_PROMPT}]},
                {"role": "model", "parts": [{"text": "Compris. Je suis Nkotronic, prÃªt Ã  aider avec le N'ko de maniÃ¨re concise et efficace."}]},
                # Message de bienvenue (visible pour l'utilisateur)
                {"role": "user", "parts": [{"text": "Bonjour"}]},
                {"role": "model", "parts": [{"text": SYSTEM_MESSAGE}]}
            ],
            created_at=datetime.now(),
            last_activity=datetime.now(),
            message_count=0
        )
        logger.info(f"âœ¨ Nouvelle session crÃ©Ã©e: {session_id}")
    
    return sessions[session_id]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/")
async def root():
    """Endpoint racine"""
    return {
        "service": "Nkotronic API",
        "version": "2.1.0",
        "status": "running",
        "model": "gemini-2.5-flash",
        "uptime_seconds": (datetime.now() - SERVER_START_TIME).total_seconds(),
        "active_sessions": len(sessions),
        "optimizations": [
            "System prompt optimisÃ©",
            f"Historique limitÃ© Ã  {MAX_HISTORY_MESSAGES} messages"
        ]
    }

@app.get("/health")
async def health_check():
    """
    âœ… Endpoint de health check avec dÃ©tection de cold start
    """
    uptime = (datetime.now() - SERVER_START_TIME).total_seconds()
    is_cold_start = uptime < 5  # Cold start si uptime < 5 secondes
    
    return {
        "status": "healthy",
        "cold_start": is_cold_start,
        "uptime_seconds": uptime,
        "grammar_loaded": LOADING_STATUS["grammar_loaded"],
        "active_sessions": len(sessions),
        "model": "gemini-2.5-flash",
        "max_history": MAX_HISTORY_MESSAGES
    }

@app.get("/loading-status")
async def loading_status():
    """Status du chargement de la grammaire N'ko"""
    return LOADING_STATUS

@app.get("/sessions")
async def list_sessions():
    """Liste toutes les sessions actives"""
    return {
        "total": len(sessions),
        "sessions": [
            {
                "session_id": s.session_id,
                "created_at": s.created_at.isoformat(),
                "last_activity": s.last_activity.isoformat(),
                "message_count": s.message_count,
                "history_length": len(s.history)
            }
            for s in sessions.values()
        ]
    }

@app.delete("/session/{session_id}")
async def delete_session(session_id: str):
    """Supprime une session spÃ©cifique"""
    if session_id in sessions:
        del sessions[session_id]
        logger.info(f"ğŸ—‘ï¸  Session supprimÃ©e manuellement: {session_id}")
        return {"status": "deleted", "session_id": session_id}
    raise HTTPException(status_code=404, detail="Session introuvable")

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    âœ… Endpoint de chat avec streaming SSE et historique optimisÃ©
    """
    global FIRST_REQUEST
    
    session_id = request.session_id
    user_message = request.message
    
    logger.info(f"ğŸ“© Message reÃ§u - Session: {session_id}")
    logger.info(f"ğŸ’¬ Contenu: {user_message[:50]}...")
    
    # Cold start detection
    uptime = (datetime.now() - SERVER_START_TIME).total_seconds()
    is_cold_start = FIRST_REQUEST and uptime < 60
    
    async def generate():
        global FIRST_REQUEST
        
        # VÃ©rifier la clÃ© API
        if not GEMINI_API_KEY:
            logger.error("âŒ ClÃ© API manquante")
            yield f"data: {json.dumps({'error': 'ClÃ© API manquante'})}\n\n"
            return
        
        try:
            # Envoyer notification cold start si nÃ©cessaire
            if is_cold_start:
                logger.info("â„ï¸  Cold start dÃ©tectÃ©")
                yield f"data: {json.dumps({'cold_start': True, 'message': 'Initialisation du serveur (30-60s)...'})}\n\n"
                FIRST_REQUEST = False
            
            # RÃ©cupÃ©rer ou crÃ©er la session
            is_new_session = session_id not in sessions
            session = get_session(session_id, initialize=is_new_session)
            
            # Ajouter le message utilisateur Ã  l'historique
            session.history.append({
                "role": "user",
                "parts": [{"text": user_message}]
            })
            
            # âœ… Tronquer l'historique si nÃ©cessaire
            session.history = truncate_history(session.history, MAX_HISTORY_MESSAGES)
            
            # CrÃ©er le modÃ¨le
            model = genai.GenerativeModel(
                model_name=request.model,
                safety_settings=safety_settings
            )
            
            # GÃ©nÃ©rer la rÃ©ponse en streaming
            logger.info(f"ğŸ¤– GÃ©nÃ©ration avec {request.model} (historique: {len(session.history)} messages)...")
            
            response = model.generate_content(
                session.history,
                generation_config=genai.types.GenerationConfig(
                    temperature=request.temperature,
                    max_output_tokens=request.max_tokens,
                ),
                stream=True
            )
            
            full_response = ""
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    yield f"data: {json.dumps({'content': chunk.text})}\n\n"
            
            # Ajouter la rÃ©ponse complÃ¨te Ã  l'historique
            session.history.append({
                "role": "model",
                "parts": [{"text": full_response}]
            })
            
            # Mettre Ã  jour la session
            session.last_activity = datetime.now()
            session.message_count += 1
            
            logger.info(f"âœ… RÃ©ponse gÃ©nÃ©rÃ©e ({len(full_response)} chars)")
            
            # Envoyer le signal de fin
            yield f"data: {json.dumps({'done': True, 'message_count': session.message_count})}\n\n"
            
        except Exception as e:
            logger.error(f"âŒ Erreur: {str(e)}")
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STARTUP EVENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.on_event("startup")
async def startup_event():
    """Ã‰vÃ©nement de dÃ©marrage"""
    logger.info("â•" * 60)
    logger.info("ğŸš€ NKOTRONIC API - DÃ‰MARRAGE (VERSION OPTIMISÃ‰E)")
    logger.info("â•" * 60)
    logger.info(f"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"ğŸ¤– ModÃ¨le: gemini-2.5-flash")
    logger.info(f"ğŸ”‘ ClÃ© API: {'âœ… ConfigurÃ©e' if GEMINI_API_KEY else 'âŒ Manquante'}")
    logger.info(f"ğŸ“ Historique max: {MAX_HISTORY_MESSAGES} messages")
    logger.info(f"ğŸ’¡ System prompt: OptimisÃ© pour rÃ©ponses concises")
    logger.info("â•" * 60)
    
    # Simuler le chargement de la grammaire
    LOADING_STATUS["grammar_loaded"] = True
    LOADING_STATUS["grammar_load_time"] = datetime.now().isoformat()
    logger.info("ğŸ“š Grammaire N'ko chargÃ©e")

@app.on_event("shutdown")
async def shutdown_event():
    """Ã‰vÃ©nement d'arrÃªt"""
    logger.info("=" * 60)
    logger.info("ğŸ›‘ NKOTRONIC API - ARRÃŠT")
    logger.info(f"ğŸ“Š Sessions actives: {len(sessions)}")
    logger.info(f"â±ï¸  Uptime: {(datetime.now() - SERVER_START_TIME).total_seconds():.0f}s")
    logger.info("=" * 60)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POINT D'ENTRÃ‰E
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)