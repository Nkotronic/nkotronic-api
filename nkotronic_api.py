# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  NKOTRONIC BACKEND - VERSION GEMINI CORRIGÃ‰E               â•‘
# â•‘  âœ… Tous les endpoints nÃ©cessaires                         â•‘
# â•‘  âœ… Gestion correcte de l'historique                       â•‘
# â•‘  âœ… Cold start dÃ©tection                                   â•‘
# â•‘  âœ… Message systÃ¨me initial dans l'historique              â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import os
import json
from typing import List, Optional, Dict
from datetime import datetime, timedelta
from collections import OrderedDict
import asyncio

app = FastAPI(title="Nkotronic API - Gemini Edition", version="5.2.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROMPT SYSTÃˆME & CHARGEMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EXPLANATORY_PROMPT = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š CONTEXTE ESSENTIEL SUR LE N'KO                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Le N'ko (ß’ßß) est SIMULTANÃ‰MENT un Alphabet et une Langue.
Inventeur : FodÃ© SolomÄna KantÃª (ßßß˜ß‹ß« ß›ßŸßß¬ß¡ßŠß¯ß£ßŠß« ßßŠß²ß•ßß«).

ğŸ¯ TON RÃ”LE :
- Tu es Nkotronic, l'assistant IA expert en N'ko.
- Tu maÃ®trises la grammaire ß’ßß ßßŠß²ßœß.
- TRADUCTION TECHNIQUE : Ne simplifie JAMAIS. Utilise les termes exacts fournis :
  Ex: MÃ©tÃ©orologie = ß“ßŠß²ß˜ßŠß¦ß‹ß™ß‹ß²ßŸßß²ß˜ßß¦ßŠ, AÃ©ronautique = ß›ßŠß²ß¡ßŠß–ßŠß²ß“ßŠß²ß¡ßŠ, Pilote = ßŸßŠßœßŠß²ß ßŠ.
"""

INITIAL_SYSTEM_MESSAGE = "Alu ni djÃ¶ ! Je suis Nkotronic, votre assistant du N'ko. Que puis-je faire pour vous ?"

GRAMMAR_FILE_PATH = "Tu es Nkotronic, l'IA.txt"
NKOTRONIC_SYSTEM_PROMPT = ""
LOADING_STATUS = {
    "status": "init", 
    "message": "Initialisation...", 
    "progress": 0, 
    "loaded": False,
    "grammar_loaded": False,
    "start_time": None
}

# Variable pour dÃ©tecter le cold start
SERVER_START_TIME = datetime.now()
FIRST_REQUEST = True

def load_system_prompt():
    global NKOTRONIC_SYSTEM_PROMPT, LOADING_STATUS
    try:
        LOADING_STATUS["status"] = "loading"
        LOADING_STATUS["message"] = "Chargement de la grammaire..."
        LOADING_STATUS["progress"] = 50
        
        if os.path.exists(GRAMMAR_FILE_PATH):
            with open(GRAMMAR_FILE_PATH, 'r', encoding='utf-8') as f:
                grammar_content = f.read()
            NKOTRONIC_SYSTEM_PROMPT = EXPLANATORY_PROMPT + "\n\n" + grammar_content
            LOADING_STATUS.update({
                "status": "ready", 
                "message": "Grammaire chargÃ©e avec succÃ¨s",
                "loaded": True, 
                "grammar_loaded": True,
                "progress": 100
            })
            print(f"âœ… Grammaire chargÃ©e ({len(NKOTRONIC_SYSTEM_PROMPT)} caractÃ¨res)")
            return True
        else:
            NKOTRONIC_SYSTEM_PROMPT = EXPLANATORY_PROMPT
            LOADING_STATUS.update({
                "status": "warning", 
                "message": "Fichier grammaire manquant - Mode dÃ©gradÃ©",
                "loaded": True,
                "grammar_loaded": False,
                "progress": 100
            })
            print("âš ï¸ Fichier grammaire non trouvÃ© - Mode dÃ©gradÃ©")
            return False
    except Exception as e:
        LOADING_STATUS.update({
            "status": "error", 
            "message": f"Erreur : {str(e)}",
            "loaded": False,
            "grammar_loaded": False
        })
        print(f"âŒ Erreur chargement grammaire : {e}")
        return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GESTION DES SESSIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SessionData(BaseModel):
    history: List[Dict] = []
    last_activity: datetime
    message_count: int = 0

sessions: OrderedDict[str, SessionData] = OrderedDict()

def get_session(session_id: str, initialize: bool = False) -> SessionData:
    """RÃ©cupÃ¨re ou crÃ©e une session"""
    if session_id in sessions:
        sessions.move_to_end(session_id)
        session = sessions[session_id]
        session.last_activity = datetime.now()
        return session
    
    # Nouvelle session
    new_session = SessionData(
        history=[],
        last_activity=datetime.now(),
        message_count=0
    )
    
    # Si initialize=True, ajouter le message systÃ¨me initial
    if initialize:
        new_session.history = [
            {
                "role": "user",
                "parts": ["Bonjour"]
            },
            {
                "role": "model",
                "parts": [INITIAL_SYSTEM_MESSAGE]
            }
        ]
    
    sessions[session_id] = new_session
    
    # Limite Ã  1000 sessions max
    if len(sessions) > 1000:
        sessions.popitem(last=False)
    
    print(f"ğŸ“ Nouvelle session crÃ©Ã©e : {session_id}")
    return new_session

def cleanup_old_sessions():
    """Nettoie les sessions inactives depuis plus de 24h"""
    cutoff = datetime.now() - timedelta(hours=24)
    to_delete = [sid for sid, data in sessions.items() if data.last_activity < cutoff]
    for sid in to_delete:
        del sessions[sid]
    if to_delete:
        print(f"ğŸ§¹ {len(to_delete)} sessions nettoyÃ©es")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODÃˆLES DE DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ChatRequest(BaseModel):
    message: str
    session_id: str = "default"
    model: str = "gemini-2.5-flash"  # âœ… MEILLEUR CHOIX
    temperature: float = 0.7
    max_tokens: int = 4000

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/")
async def root():
    """Endpoint racine"""
    return {
        "status": "online",
        "service": "Nkotronic API",
        "model": "Gemini",
        "version": "5.2.0",
        "uptime_seconds": (datetime.now() - SERVER_START_TIME).total_seconds(),
        "active_sessions": len(sessions)
    }

@app.get("/health")
async def health_check():
    """Endpoint de santÃ© pour le warmup"""
    global FIRST_REQUEST
    
    # DÃ©tecter le cold start
    uptime = (datetime.now() - SERVER_START_TIME).total_seconds()
    is_cold_start = uptime < 5  # Si le serveur vient de dÃ©marrer
    
    cleanup_old_sessions()
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime_seconds": uptime,
        "cold_start": is_cold_start,
        "grammar_loaded": LOADING_STATUS.get("grammar_loaded", False),
        "active_sessions": len(sessions),
        "first_request": FIRST_REQUEST
    }

@app.get("/loading-status")
async def loading_status():
    """Status du chargement de la grammaire"""
    return LOADING_STATUS

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """Endpoint de chat avec streaming SSE"""
    global FIRST_REQUEST
    
    async def generate():
        try:
            # VÃ©rifier la clÃ© API
            api_key = os.environ.get("GEMINI_API_KEY")
            if not api_key:
                yield f"data: {json.dumps({'error': 'ClÃ© API Gemini manquante'})}\n\n"
                return

            # Configurer Gemini
            genai.configure(api_key=api_key)
            
            # Configuration de sÃ©curitÃ© : autoriser tout
            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }

            # CrÃ©er le modÃ¨le
            model = genai.GenerativeModel(
                model_name=request.model,
                system_instruction=NKOTRONIC_SYSTEM_PROMPT,
                safety_settings=safety_settings
            )

            # RÃ©cupÃ©rer ou crÃ©er la session
            is_new_session = request.session_id not in sessions
            session = get_session(request.session_id, initialize=is_new_session)
            
            # DÃ©tecter le cold start (premiÃ¨re requÃªte aprÃ¨s dÃ©marrage)
            uptime = (datetime.now() - SERVER_START_TIME).total_seconds()
            is_cold_start = FIRST_REQUEST and uptime < 60
            
            if is_cold_start:
                FIRST_REQUEST = False
                # Informer le frontend qu'il y a eu un cold start
                yield f"data: {json.dumps({
                    'cold_start': True,
                    'message': 'Initialisation du serveur...'
                })}\n\n"
                # Petit dÃ©lai pour que le frontend affiche le message
                await asyncio.sleep(0.5)
            
            # CrÃ©er le chat avec l'historique
            chat = model.start_chat(history=session.history)
            
            # Envoyer le message avec streaming
            full_response = ""
            response_stream = chat.send_message(
                request.message,
                stream=True,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=request.max_tokens,
                    temperature=request.temperature,
                )
            )
            
            # Streamer la rÃ©ponse
            for chunk in response_stream:
                if chunk.text:
                    full_response += chunk.text
                    yield f"data: {json.dumps({'content': chunk.text})}\n\n"
            
            # Mettre Ã  jour l'historique de la session
            session.history = chat.history
            session.last_activity = datetime.now()
            session.message_count += 1
            
            # Signal de fin
            yield f"data: {json.dumps({
                'done': True, 
                'session_id': request.session_id,
                'message_count': session.message_count
            })}\n\n"
            
            print(f"âœ… Message traitÃ© pour session {request.session_id} (total: {session.message_count})")
            
        except Exception as e:
            print(f"âŒ Erreur streaming : {e}")
            yield f"data: {json.dumps({'error': str(e)})}\n\n"
    
    return StreamingResponse(generate(), media_type="text/event-stream")

@app.delete("/session/{session_id}")
async def delete_session(session_id: str):
    """Supprimer une session"""
    if session_id in sessions:
        del sessions[session_id]
        return {"status": "deleted", "session_id": session_id}
    return {"status": "not_found", "session_id": session_id}

@app.get("/sessions")
async def list_sessions():
    """Liste toutes les sessions actives"""
    return {
        "total": len(sessions),
        "sessions": [
            {
                "id": sid,
                "message_count": data.message_count,
                "last_activity": data.last_activity.isoformat()
            }
            for sid, data in sessions.items()
        ]
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ã‰VÃ‰NEMENTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.on_event("startup")
async def startup():
    """Chargement au dÃ©marrage"""
    print("ğŸš€ DÃ©marrage de Nkotronic API...")
    LOADING_STATUS["start_time"] = datetime.now().isoformat()
    load_system_prompt()
    print(f"âœ… Serveur prÃªt - {len(sessions)} sessions actives")

@app.on_event("shutdown")
async def shutdown():
    """Nettoyage Ã  l'arrÃªt"""
    print("ğŸ‘‹ ArrÃªt de Nkotronic API...")
    sessions.clear()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)